{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab1bda86",
   "metadata": {},
   "source": [
    "# Introduction to Embeddings with the OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a036b7",
   "metadata": {},
   "source": [
    "# 1. What are Embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d69b01",
   "metadata": {},
   "source": [
    "## The wonderful world of embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35a75b8",
   "metadata": {},
   "source": [
    "### Creating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc699ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an OpenAI client and set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create a request to obtain embeddings\n",
    "response = client.embeddings.create(\n",
    "  model=\"text-embedding-ada-002\",\n",
    "  input=\"This can contain any text.\"\n",
    ")\n",
    "\n",
    "# Convert the response into a dictionary\n",
    "response_dict = response.model_dump()\n",
    "\n",
    "print(response_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10707aca",
   "metadata": {},
   "source": [
    "### Digging into the embeddings response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9de3768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the total_tokens from response_dict\n",
    "print(response_dict['usage']['total_tokens'])\n",
    "\n",
    "\"\"\" \n",
    "11 \n",
    "{'data': [{'embedding': [-0.010771304368972778, -0.01712021790444851, 0.02336982451379299, -0.03116859309375286, \n",
    "-0.014141061343252659, 0.03503487631678581, -0.011731254868209362, -0.007620019372552633, -0.003634570399299264, \n",
    "-0.04260855168104172, 0.010532972402870655, 0.012532317079603672, 0.02554129809141159, -0.0031694911886006594, \n",
    "-0.004415771458297968, 0.0038000792264938354, 0.015359205193817616, -0.002889781491830945, 0.0037802180740982294, \n",
    "-0.01655086688697338, -0.028811750933527946, 0.023303620517253876, 0.021913347765803337, -0.011029497720301151, \n",
    "-0.008176128380000591, 0.000987259205430746, 0.007639880292117596 ..... \n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the embeddings from response_dict\n",
    "print(response_dict['data'][0]['embedding'])\n",
    "\n",
    "\"\"\"\n",
    "    [-0.010771304368972778, -0.01712021790444851, 0.02336982451379299, -0.03116859309375286, -0.014141061343252659, \n",
    "    0.03503487631678581, -0.011731254868209362, -0.007620019372552633, -0.003634570399299264\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16ce4ee",
   "metadata": {},
   "source": [
    "## Investigating the vector space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d91df97",
   "metadata": {},
   "source": [
    "### Embedding product descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b0387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Extract a list of product short descriptions from products\n",
    "product_descriptions = [product['short_description'] for product in products]\n",
    "\n",
    "# Create embeddings for each product description\n",
    "response = client.embeddings.create(\n",
    "  model=\"text-embedding-ada-002\",\n",
    "  input=product_descriptions\n",
    ")\n",
    "response_dict = response.model_dump()\n",
    "\n",
    "# Extract the embeddings from response_dict and store in products\n",
    "for i, product in enumerate(products):\n",
    "    product['embedding'] = response_dict['data'][i]['embedding']\n",
    "    \n",
    "print(products[0].items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acd09e6",
   "metadata": {},
   "source": [
    "### Visualizing the embedded descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604fc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reviews and embeddings lists using list comprehensions\n",
    "categories = [product['category'] for product in products]\n",
    "embeddings = [product['embedding'] for product in products]\n",
    "\n",
    "# Reduce the number of embeddings dimensions to two using t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=5)\n",
    "embeddings_2d = tsne.fit_transform(np.array(embeddings))\n",
    "\n",
    "# Create a scatter plot from embeddings_2d\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    plt.annotate(category, (embeddings_2d[i, 0], embeddings_2d[i, 1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfb7f41",
   "metadata": {},
   "source": [
    "## Text similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366f23d9",
   "metadata": {},
   "source": [
    "### More repeatable embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ec30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Define a create_embeddings function\n",
    "def create_embeddings(texts):\n",
    "  response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=texts\n",
    "  )\n",
    "  response_dict = response.model_dump()\n",
    "\n",
    "  return [data['embedding'] for data in response_dict['data']]\n",
    "\n",
    "# Embed short_description and print\n",
    "print(create_embeddings(short_description)[0])\n",
    "\n",
    "# Embed list_of_descriptions and print\n",
    "print(create_embeddings(list_of_descriptions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b52e0",
   "metadata": {},
   "source": [
    "### Finding the most similar product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e82f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Embed the search text\n",
    "search_text = \"soap\"\n",
    "search_embedding = create_embeddings(search_text)[0]\n",
    "\n",
    "distances = []\n",
    "for product in products:\n",
    "  # Compute the cosine distance for each product description\n",
    "  dist = distance.cosine(search_embedding, product[\"embedding\"])\n",
    "  distances.append(dist)\n",
    "\n",
    "# Find and print the most similar product short_description    \n",
    "min_dist_ind = np.argmin(distances)\n",
    "print(products[min_dist_ind]['short_description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3e635",
   "metadata": {},
   "source": [
    "# 2. Embeddings for AI Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28249061",
   "metadata": {},
   "source": [
    "## Semantic search and enriched embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c8cb81",
   "metadata": {},
   "source": [
    "### Enriching embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4f3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Define a function to combine the relevant features into a single string\n",
    "def create_product_text(product):\n",
    "  return f\"\"\"Title: {product['title']}\n",
    "Description: {product['short_description']}\n",
    "Category: {product['category']}\n",
    "Features: {'; '.join(product['features'])}\"\"\"\n",
    "\n",
    "# Combine the features for each product\n",
    "product_texts = [create_product_text(product) for product in products]\n",
    "\n",
    "# Create the embeddings from product_texts\n",
    "product_embeddings = create_embeddings(product_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c057ea",
   "metadata": {},
   "source": [
    "### Sorting by similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6649d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_n_closest(query_vector, embeddings, n=3):\n",
    "  distances = []\n",
    "  for index, embedding in enumerate(embeddings):\n",
    "    # Calculate the cosine distance between the query vector and embedding\n",
    "    dist = distance.cosine(query_vector, embedding)\n",
    "    # Append the distance and index to distances\n",
    "    distances.append({\"distance\": dist, \"index\": index})\n",
    "  # Sort distances by the distance key\n",
    "  distances_sorted = sorted(distances, key=lambda x: x[\"distance\"])\n",
    "  # Return the first n elements in distances_sorted\n",
    "  return distances_sorted[0:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b30e7bc",
   "metadata": {},
   "source": [
    "### Semantic search for products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e53dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create the query vector from query_text\n",
    "query_text = \"computer\"\n",
    "query_vector = create_embeddings(query_text)[0]\n",
    "\n",
    "# Find the five closest distances\n",
    "hits = find_n_closest(query_vector, product_embeddings, n=5)\n",
    "\n",
    "print(f'Search results for \"{query_text}\"')\n",
    "for hit in hits:\n",
    "  # Extract the product at each index in hits\n",
    "  product = products[hit['index']]\n",
    "  print(product[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d7ba50",
   "metadata": {},
   "source": [
    "## Recommendation systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b91d97",
   "metadata": {},
   "source": [
    "### Product recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82011439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Combine the features for last_product and each product in products\n",
    "last_product_text = create_product_text(last_product)\n",
    "product_texts = [create_product_text(product) for product in products]\n",
    "\n",
    "# Embed last_product_text and product_texts\n",
    "last_product_embeddings = create_embeddings(last_product_text)[0]\n",
    "product_embeddings = create_embeddings(product_texts)\n",
    "\n",
    "# Find the three smallest cosine distances and their indexes\n",
    "hits = find_n_closest(last_product_embeddings, product_embeddings)\n",
    "\n",
    "for hit in hits:\n",
    "  product = products[hit['index']]\n",
    "  print(product['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f2ad6a",
   "metadata": {},
   "source": [
    "### Adding user history to the recommendation engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3103ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Prepare and embed the user_history, and calculate the mean embeddings\n",
    "history_texts = [create_product_text(product) for product in user_history]\n",
    "history_embeddings = create_embeddings(history_texts)\n",
    "mean_history_embeddings = np.mean(history_embeddings, axis=0)\n",
    "\n",
    "# Filter products to remove any in user_history\n",
    "products_filtered = [product for product in products if product not in user_history]\n",
    "\n",
    "# Combine product features and embed the resulting texts\n",
    "product_texts = [create_product_text(product) for product in products_filtered]\n",
    "product_embeddings = create_embeddings(product_texts)\n",
    "\n",
    "hits = find_n_closest(mean_history_embeddings, product_embeddings)\n",
    "\n",
    "for hit in hits:\n",
    "  product = products_filtered[hit['index']]\n",
    "  print(product['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d23ca",
   "metadata": {},
   "source": [
    "## Embeddings for classification tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f52315d",
   "metadata": {},
   "source": [
    "### Embedding restaurant reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf2adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create a list of class descriptions from the sentiment labels\n",
    "class_descriptions = [sentiment['label'] for sentiment in sentiments]\n",
    "\n",
    "# Embed the class_descriptions and reviews\n",
    "class_embeddings = create_embeddings(class_descriptions)\n",
    "review_embeddings = create_embeddings(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ba47c",
   "metadata": {},
   "source": [
    "### Classifying review sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ce0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to return the minimum distance and its index\n",
    "def find_closest(query_vector, embeddings):\n",
    "  distances = []\n",
    "  for index, embedding in enumerate(embeddings):\n",
    "    dist = distance.cosine(query_vector, embedding)\n",
    "    distances.append({\"distance\": dist, \"index\": index})\n",
    "  return min(distances, key=lambda x: x[\"distance\"])\n",
    "\n",
    "for index, review in enumerate(reviews):\n",
    "  # Find the closest distance and its index using find_closest()\n",
    "  closest = find_closest(review_embeddings[index], class_embeddings)\n",
    "  # Subset sentiments using the index from closest\n",
    "  label = sentiments[closest['index']]['label']\n",
    "  print(f'\"{review}\" was classified as {label}')\n",
    "\n",
    "\"\"\"\n",
    "    \"The food was delicious!\" was classified as Positive\n",
    "    \"The service was a bit slow but the food was good\" was classified as Neutral\n",
    "    \"Never going back!\" was classified as Positive\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc17364",
   "metadata": {},
   "source": [
    "### Embedding more detailed descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e168816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Extract and embed the descriptions from sentiments\n",
    "class_descriptions = [sentiment['description'] for sentiment in sentiments]\n",
    "class_embeddings = create_embeddings(class_descriptions)\n",
    "review_embeddings = create_embeddings(reviews)\n",
    "\n",
    "def find_closest(query_vector, embeddings):\n",
    "  distances = []\n",
    "  for index, embedding in enumerate(embeddings):\n",
    "    dist = distance.cosine(query_vector, embedding)\n",
    "    distances.append({\"distance\": dist, \"index\": index})\n",
    "  return min(distances, key=lambda x: x[\"distance\"])\n",
    "\n",
    "for index, review in enumerate(reviews):\n",
    "  closest = find_closest(review_embeddings[index], class_embeddings)\n",
    "  label = sentiments[closest['index']]['label']\n",
    "  print(f'\"{review}\" was classified as {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6367788f",
   "metadata": {},
   "source": [
    "# 3. Vector Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c69bb3",
   "metadata": {},
   "source": [
    "## Vector databases for embedding systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9cd34a",
   "metadata": {},
   "source": [
    "## Creating vector databases with ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9224a4",
   "metadata": {},
   "source": [
    "### Getting started with ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934481d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a persistant client\n",
    "client = chromadb.PersistentClient()\n",
    "\n",
    "# Create a netflix_title collection using the OpenAI Embedding function\n",
    "collection = client.create_collection(\n",
    "  name=\"netflix_titles\",\n",
    "  embedding_function=OpenAIEmbeddingFunction(api_key=\"<OPENAI_API_TOKEN>\")\n",
    ")\n",
    "\n",
    "# List the collections\n",
    "print(client.list_collections())\n",
    "\n",
    "# [Collection(name=netflix_titles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a5fa85",
   "metadata": {},
   "source": [
    "### Estimating embedding costs with tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dbb343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the encoder for the OpenAI text-embedding-ada-002 model\n",
    "enc = tiktoken.encoding_for_model(\"text-embedding-ada-002\")\n",
    "\n",
    "# Encode each text in documents and calculate the total tokens\n",
    "total_tokens = sum(len(enc.encode(text)) for text in documents)\n",
    "\n",
    "cost_per_1k_tokens = 0.0001\n",
    "\n",
    "# Display number of tokens and cost\n",
    "print('Total tokens:', total_tokens)\n",
    "print('Cost:', cost_per_1k_tokens * total_tokens/1000)\n",
    "\n",
    "\"\"\"\n",
    "    Total tokens: 51226\n",
    "    Cost: 0.005122600000000001\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6106a3",
   "metadata": {},
   "source": [
    "### Adding data to the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ecae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the netflix_titles collection\n",
    "collection = client.create_collection(\n",
    "  name=\"netflix_titles\",\n",
    "  embedding_function=OpenAIEmbeddingFunction(api_key=\"<OPENAI_API_TOKEN>\")\n",
    ")\n",
    "\n",
    "# Add the documents and IDs to the collection\n",
    "collection.add(ids=ids, documents=documents)\n",
    "\n",
    "# Print the collection size and first ten items\n",
    "print(f\"No. of documents: {collection.count()}\")\n",
    "print(f\"First ten documents: {collection.peek()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8ededc",
   "metadata": {},
   "source": [
    "## Querying and updating the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd212b3",
   "metadata": {},
   "source": [
    "### Querying the Netflix collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46391a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the netflix_titles collection\n",
    "collection = client.get_collection(\n",
    "  name=\"netflix_titles\",\n",
    "  embedding_function=OpenAIEmbeddingFunction(api_key=\"<OPENAI_API_TOKEN>\")\n",
    ")\n",
    "\n",
    "# Query the collection for \"films about dogs\"\n",
    "result = collection.query(\n",
    "  query_texts=[\"films about dogs\"],\n",
    "  n_results=3\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67cef5",
   "metadata": {},
   "source": [
    "### Updating and deleting items from a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acea310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the netflix_titles collection\n",
    "collection = client.get_collection(\n",
    "  name=\"netflix_titles\",\n",
    "  embedding_function=OpenAIEmbeddingFunction(api_key=\"<OPENAI_API_TOKEN>\")\n",
    ")\n",
    "\n",
    "# Update or add the new documents\n",
    "collection.upsert(\n",
    "  ids=[doc['id'] for doc in new_data],\n",
    "  documents=[doc['document'] for doc in new_data]\n",
    ")\n",
    "\n",
    "# Delete the item with ID \"s95\" and re-run the query\n",
    "collection.delete(ids=[\"s95\"])\n",
    "\n",
    "result = collection.query(\n",
    "  query_texts=[\"films about dogs\"],\n",
    "  n_results=3\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66becf86",
   "metadata": {},
   "source": [
    "## Multiple queries and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a27c49",
   "metadata": {},
   "source": [
    "### Querying with multiple texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the netflix_titles collection\n",
    "collection = client.get_collection(\n",
    "  name=\"netflix_titles\",\n",
    "  embedding_function=OpenAIEmbeddingFunction(api_key=\"<OPENAI_API_TOKEN>\")\n",
    ")\n",
    "\n",
    "reference_ids = ['s999', 's1000']\n",
    "\n",
    "# Retrieve the documents for the reference_ids\n",
    "reference_texts = collection.get(ids=reference_ids)['documents']\n",
    "\n",
    "# Query using reference_texts\n",
    "result = collection.query(\n",
    "  query_texts=reference_texts,\n",
    "  n_results=3\n",
    ")\n",
    "\n",
    "print(result['documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3797625c",
   "metadata": {},
   "source": [
    "### Filtering using metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b9172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the netflix_titles collection\n",
    "collection = client.get_collection(\n",
    "  name=\"netflix_titles\",\n",
    "  embedding_function=OpenAIEmbeddingFunction(api_key=\"<OPENAI_API_TOKEN>\")\n",
    ")\n",
    "\n",
    "reference_texts = [\"children's story about a car\", \"lions\"]\n",
    "\n",
    "# Query two results using reference_texts\n",
    "result = collection.query(\n",
    "  query_texts=reference_texts,\n",
    "  n_results=2,\n",
    "  # Filter for titles with a G rating released before 2019\n",
    "  where={\n",
    "    \"$and\": [\n",
    "        {\"rating\": \n",
    "        \t{\"$eq\": \"G\"}\n",
    "        },\n",
    "        {\"release_year\": \n",
    "         \t{\"$lt\": 2019}\n",
    "        }\n",
    "    ]\n",
    "  }\n",
    ")\n",
    "\n",
    "print(result['documents'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
