{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e3aebc1",
   "metadata": {},
   "source": [
    "# ChatGPT Prompt Engineering for Developers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb30707",
   "metadata": {},
   "source": [
    "## 1. Introduction to Prompt Engineering Best Practices\n",
    "\n",
    "### Creating the get_response() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82cc3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "def get_response(prompt):\n",
    "  # Create a request to the chat completions endpoint\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    # Assign the role and content for the message\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}], \n",
    "    temperature = 0)\n",
    "  return response.choices[0].message.content\n",
    "\n",
    "# Test the function with your prompt\n",
    "response = get_response(\"Write a poem about ChatGPT\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b182a9",
   "metadata": {},
   "source": [
    "### Exploring prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8675a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Craft a prompt that follows the instructions\n",
    "prompt = \"Write a poem about ChatGPT. Use basic English that a child can understand.\"\n",
    "\n",
    "# Get the response\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514a563",
   "metadata": {},
   "source": [
    "### Using delimited prompts with f-strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b070cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create a prompt that completes the story\n",
    "prompt = f\"\"\"Complete the story delimited by triple backticks. \n",
    " ```{story}```\"\"\"\n",
    "\n",
    "# Get the generated response \n",
    "response = get_response(prompt)\n",
    "\n",
    "print(\"\\n Original story: \\n\", story)\n",
    "print(\"\\n Generated story: \\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ce0fb",
   "metadata": {},
   "source": [
    "### Building specific and precise prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2878aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create a request to complete the story\n",
    "prompt = f\"\"\"Complete the story delimited by triple backticks with only two paragraphs using the style of William Shakespeare. \n",
    " ```{story}```\"\"\"\n",
    "\n",
    "# Get the generated response\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(\"\\n Original story: \\n\", story)\n",
    "print(\"\\n Generated story: \\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2e3ee7",
   "metadata": {},
   "source": [
    "### Generating a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108f7e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create a prompt that generates the table\n",
    "prompt = \"Generate a table containing 10 books I should read if I am a sci-fi lover, with columns for Title, Author, and Year.\"\n",
    "\n",
    "# Get the response\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83193a7a",
   "metadata": {},
   "source": [
    "### Customizing output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1520ac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create the instructions\n",
    "instructions = \"You will be provided with a text delimited by triple backticks. Infer its language, then generate a suitable title for it. \"\n",
    "\n",
    "# Create the output format\n",
    "output_format = \"\"\"Use the following format for the output:\n",
    "         - Text: <the text>\n",
    "         - Language: <the text language>\n",
    "         - Title: <the generated title>\"\"\"\n",
    "\n",
    "# Create the final prompt\n",
    "prompt = instructions + output_format + f\"```{text}```\"\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96b164",
   "metadata": {},
   "source": [
    "### Using conditional prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd71f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create the instructions\n",
    "instructions = \"You will be provided with a text delimited by triple backticks. Infer its language and the number of sentences it contains. Then, if the text has more than one sentence, generate a suitable title for it. Otherwise, if the text contains only one sentence, write 'N/A' for the title.\"\n",
    "\n",
    "# Create the output format\n",
    "output_format = \"\"\"The output should follow this format:\n",
    "          - Text: <the given text>\n",
    "          - Language: <the text language>\n",
    "          - N_sentences: <number of sentences>\n",
    "          - Title: <the generated title>'.\"\"\"\n",
    "\n",
    "prompt = instructions + output_format + f\"```{text}```\"\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5ad924",
   "metadata": {},
   "source": [
    "## 2. Advanced Prompt Engineering Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e13439",
   "metadata": {},
   "source": [
    "## Few-shot prompting\n",
    "\n",
    "### Controlling output structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca3482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create a one-shot prompt\n",
    "prompt = \"\"\"\n",
    "     Q: Extract the odd numbers from {1, 3, 7, 12, 19}. A: Odd numbers = {1, 3, 7, 19}\n",
    "     Q: Extract the odd numbers from {3, 5, 11, 12, 16}. A:\n",
    "\"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f39b1f",
   "metadata": {},
   "source": [
    "### Sentiment analysis with few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea76c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model = \"gpt-3.5-turbo\",\n",
    "  # Provide the examples as previous conversations\n",
    "  messages = [{\"role\": \"user\",\n",
    "  \t\t     \"content\": \"The product quality exceeded my expectations\"},\n",
    "              {\"role\": \"assistant\",\n",
    "  \t\t     \"content\": \"1\"},\n",
    "              {\"role\": \"user\",\n",
    "  \t\t     \"content\": \"I had a terrible experience with this product's customer service\"},\n",
    "              {\"role\": \"assistant\",\n",
    "  \t\t     \"content\": \"-1\"}, \n",
    "              # Provide the text for the model to classify\n",
    "              {\"role\": \"user\",\n",
    "  \t\t     \"content\": \"The price of the product is really fair given its features\"}\n",
    "             ],\n",
    "  temperature = 0\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694adb04",
   "metadata": {},
   "source": [
    "## Multi-step prompting\n",
    "\n",
    "### Single-step prompt to plan a trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b024958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create a single-step prompt to get help planning the vacation\n",
    "prompt = \"Help me plan a beach vacation.\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13399aa",
   "metadata": {},
   "source": [
    "### Multi-step prompt to plan a trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create a prompt detailing steps to plan the trip\n",
    "prompt = \"\"\"\n",
    "     Help me plan a beach vacation.\n",
    "     Step 1 - Specify four potential locations for beach vacations\n",
    "     Step 2 - State some accommodation options in each\n",
    "     Step 3 - State activities that could be done in each\n",
    "     Step 4 - Evaluate the pros and cons for each destination\n",
    "    \"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f975cb56",
   "metadata": {},
   "source": [
    "### Analyze solution correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f15ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "code = '''\n",
    "def calculate_rectangle_area(length, width):\n",
    "    area = length * width\n",
    "    return area\n",
    "'''\n",
    "\n",
    "# Create a prompt that analyzes correctness of the code\n",
    "prompt = f\"\"\"\n",
    "     Analyze the correctness of the function delimited by triple backticks according to the following criteria:\n",
    "      1- It should have correct syntax\n",
    "      2- The function should receive only 2 inputs\n",
    "      3- The function should return only one output\n",
    "      ```{code}```\n",
    "    \"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7a4a26",
   "metadata": {},
   "source": [
    "## Chain-of-thought and self-consistency prompting\n",
    "\n",
    "### Reasoning with chain-of-thought prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56293bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create the chain-of-thought prompt\n",
    "prompt = \"Compute the age of my friend's father in 10 years, given that now he's double my friend's age, and my friend is 20. Give a step by step explanation.\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46900ce",
   "metadata": {},
   "source": [
    "### One-shot chain-of-thought prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887b867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Define the example \n",
    "example = \"\"\"Q: Sum the even numbers in the following set: {9, 10, 13, 4, 2}.\n",
    "             A: Even numbers: 10, 4, 2. Adding them: 10+4+2=16\"\"\"\n",
    "\n",
    "# Define the question\n",
    "question = \"\"\"Q: Sum the even numbers in the following set: {15, 13, 82, 7, 14} \n",
    "             A:\"\"\"\n",
    "\n",
    "# Create the final prompt\n",
    "prompt = example + question\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31422833",
   "metadata": {},
   "source": [
    "### Self-consistency prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1414bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create the self_consistency instruction\n",
    "self_consistency_instruction = \"Imagine three completely independent experts who reason differently are answering this question. The final answer is obtained by majority vote. The question is: \"\n",
    "\n",
    "# Create the problem to solve\n",
    "problem_to_solve = \"If you own a store that sells laptops and mobile phones. You start your day with 50 devices in the store, out of which 60% are mobile phones. Throughout the day, three clients visited the store, each of them bought one mobile phone, and one of them bought additionally a laptop. Also, you added to your collection 10 laptops and 5 mobile phones. How many laptops and mobile phones do you have by the end of the day?\"\n",
    "\n",
    "# Create the final prompt\n",
    "prompt = self_consistency_instruction + problem_to_solve\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d30a21",
   "metadata": {},
   "source": [
    "## Iterative prompt engineering and refinement\n",
    "\n",
    "### Iterative prompt engineering for standard prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d1e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Refine the following prompt\n",
    "prompt = \"Generate a table that contains the top 10 pre-trained language models, with columns for language model, release year, and owners.\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f54888c",
   "metadata": {},
   "source": [
    "### Iterative prompt engineering for few-shot prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c126e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Refine the following prompt\n",
    "prompt = \"\"\"\n",
    "Receiving a promotion at work made me feel on top of the world -> Happiness\n",
    "The movie's ending left me with a heavy feeling in my chest -> Sadness\n",
    "Walking alone in the dark alley sent shivers down my spine -> Fear\n",
    "School begins tomorrow -> No explicit emotion\n",
    "Time flies like an arrow ->\n",
    "\"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7becf85",
   "metadata": {},
   "source": [
    "## 3. Prompt Engineering for Business Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fd0305",
   "metadata": {},
   "source": [
    "## Text summarization and expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2561db",
   "metadata": {},
   "source": [
    "### Market research report summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f5429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Craft a prompt to summarize the report\n",
    "prompt = f\"\"\"\n",
    "Summarize the report delimited by triple backticks with a maximum of 5 sentences, while focusing on aspects related to AI and data privacy.\n",
    " ```{report}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(\"Summarized report: \\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d795b",
   "metadata": {},
   "source": [
    "### Product features summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Craft a prompt to summarize the product description\n",
    "prompt = f\"\"\"\n",
    "Summarize the product description delimited by triple backticks, in at most five bullet points while focusing on the product features and specifications\n",
    " ```{product_description}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(\"Original description: \\n\", product_description)\n",
    "print(\"Summarized description: \\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2499afeb",
   "metadata": {},
   "source": [
    "### Product description expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Craft a prompt to expand the product's description\n",
    "prompt = f\"\"\"\n",
    "Expand the product description for the Smart Home Security Camera delimited by triple backticks to provide a comprehensive overview of its features, benefits, potential applications, without bypassing the limit of one paragraph. \n",
    " ```{product_description}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(\"Original description: \\n\", product_description)\n",
    "print(\"Expanded description: \\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265421ca",
   "metadata": {},
   "source": [
    "## Text transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1837e",
   "metadata": {},
   "source": [
    "### Translation for multilingual communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07af4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Craft a prompt that translates\n",
    "prompt = f\"\"\"Translate the English marketing message delimited by triple backticks to French, Spanish, and Japanese\n",
    " ```{marketing_message}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(\"English:\", marketing_message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce0d1c1",
   "metadata": {},
   "source": [
    "### Tone adjustment for email marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35206fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Craft a prompt to change the email's tone\n",
    "prompt = f\"\"\"\n",
    "Write the email delimited by triple backticks using a professional, positive, and user-centric tone:\n",
    " ```{sample_email}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(\"Before transformation: \\n\", sample_email)\n",
    "print(\"After transformation: \\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4addeb3",
   "metadata": {},
   "source": [
    "### Writing improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f213c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Craft a prompt to transform the text\n",
    "prompt = f\"\"\"Transform the text delimited by triple backticks with the following two steps:\n",
    "Step 1 - Proofread it without changing its structure\n",
    "Step 2 - Change the tone to be formal and friendly\n",
    " ```{text}```\"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(\"Before transformation:\\n\", text)\n",
    "print(\"After transformation:\\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd1e41",
   "metadata": {},
   "source": [
    "## Text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b44b3dc",
   "metadata": {},
   "source": [
    "### Customer support ticket routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Craft a prompt to classify the ticket\n",
    "prompt = f\"\"\"Classify the ticket delimited by triple backticks as technical issue, billing inquiry, or product feedback. Your response should just contain the class and nothing else.\n",
    " ```{ticket}```\"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(\"Ticket: \", ticket)\n",
    "print(\"Class: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18fdcd7",
   "metadata": {},
   "source": [
    "### Customer support ticket analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736fdd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Craft a few-shot prompt to get the ticket's entities\n",
    "prompt = f\"\"\"Ticket: {ticket_1} -> Entities: {entities_1}\n",
    "            Ticket: {ticket_2} -> Entities: {entities_2}\n",
    "            Ticket: {ticket_3} -> Entities: {entities_3}\n",
    "            Ticket: {ticket_4} -> Entities: \"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(\"Ticket: \", ticket_4)\n",
    "print(\"Entities: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7df4f6",
   "metadata": {},
   "source": [
    "## Code generation and explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f288bda",
   "metadata": {},
   "source": [
    "### Code generation with problem description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae1e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Craft a prompt that asks the model for the function\n",
    "prompt = \"Write a Python function that accepts a list of 12 numbers representing sales for each month of the year, and outputs the month with the highest sales value\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e8b7ee",
   "metadata": {},
   "source": [
    "### Input-output examples for code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8597fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "examples=\"\"\"input = [10, 5, 8] -> output = 24\n",
    "input = [5, 2, 4] -> output = 12\n",
    "input = [2, 1, 3] -> output = 7\n",
    "input = [8, 4, 6] -> output = 19\n",
    "\"\"\"\n",
    "\n",
    "# Craft a prompt that asks the model for the function\n",
    "prompt = f\"\"\"You are provided with input-output examples delimited by triple backticks for a Python function where different factors are associated with project completion time. Each example includes numerical values for the factors and the corresponding estimated completion time. Write a code for this function.\n",
    " ```{examples}```\"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf9e2af",
   "metadata": {},
   "source": [
    "### Modifying code with multi-step prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a48284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "function = \"\"\"def calculate_area_rectangular_floor(width, length):\n",
    "\t\t\t\t\treturn width*length\"\"\"\n",
    "\n",
    "# Craft a multi-step prompt that asks the model to adjust the function\n",
    "prompt = f\"\"\"Modify the script delimited by triple backticks as follows:\n",
    "             - The function should return the perimeter of the rectangular floor as well.\n",
    "             - The inputs (floor dimensions) should be positive. Otherwise, appropriate error messages should be displayed.\n",
    "           ```{function}```\"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ebe810",
   "metadata": {},
   "source": [
    "### Explaining code step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b734ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Craft a chain-of-thought prompt that asks the model to explain what the function does\n",
    "prompt = f\"\"\"Explain what the function delimited by triple backticks does. Let's think step by step\n",
    " ```{function}```\n",
    "\"\"\"\n",
    " \n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25966b48",
   "metadata": {},
   "source": [
    "## 4. Prompt Engineering for Chatbot Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22273650",
   "metadata": {},
   "source": [
    "## Prompt engineering for chatbot development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81cc1ab",
   "metadata": {},
   "source": [
    "### Creating a dual-prompt get_response() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5befe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "def get_response(system_prompt, user_prompt):\n",
    "  # Assign the role and content for each message\n",
    "  messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "      \t\t  {\"role\": \"user\", \"content\": user_prompt}]  \n",
    "  response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\", messages= messages, temperature=0)\n",
    "\n",
    "  return response.choices[0].message.content\n",
    "\n",
    "# Try the function with a system and user prompt of your choice \n",
    "response = get_response(\"You are an expert data scientist that explains complex concepts in understandable terms\", \"Define AI\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06962ba",
   "metadata": {},
   "source": [
    "### Customer support chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f213b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Define the purpose of the chatbot\n",
    "chatbot_purpose = \"You are the customer support chatbot for an e-commerce platform specializing in electronics. Your role is to assist customers with inquiries, order tracking, and troubleshooting common issues related to their purchases. \"\n",
    "\n",
    "# Define audience guidelines\n",
    "audience_guidelines = \"Your primary audience consists of tech-savvy individuals who are interested in purchasing electronic gadgets. \"\n",
    "\n",
    "# Define tone guidelines\n",
    "tone_guidelines = \"Maintain a professional and user-friendly tone in your responses.\"\n",
    "\n",
    "base_system_prompt = chatbot_purpose + audience_guidelines + tone_guidelines\n",
    "response = get_response(base_system_prompt, \"My new headphones aren't connecting to my device\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d928136",
   "metadata": {},
   "source": [
    "### Behavioral control of a customer support chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cde6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Define the order number condition\n",
    "order_number_condition = \"If the user is asking about an order, and did not specify the order number, reply by asking for this number. \"\n",
    "\n",
    "# Define the technical issue condition\n",
    "technical_issue_condition = \"If the user is talking about a technical issue, start your response with `I'm sorry to hear about your issue with ...` \"\n",
    "\n",
    "# Create the refined system prompt\n",
    "refined_system_prompt = base_system_prompt + order_number_condition + technical_issue_condition\n",
    "\n",
    "response_1 = get_response(refined_system_prompt, \"My laptop screen is flickering. What should I do?\")\n",
    "response_2 = get_response(refined_system_prompt, \"Can you help me track my recent order?\")\n",
    "\n",
    "print(\"Response 1: \", response_1)\n",
    "print(\"Response 2: \", response_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f767a6a",
   "metadata": {},
   "source": [
    "## Role-playing prompts for chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aac0136",
   "metadata": {},
   "source": [
    "### Learning advisor chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d816769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Craft the system_prompt using the role-playing approach\n",
    "system_prompt = \"Act as a learning advisor who receives queries from users mentioning their background, experience, and goals, and accordingly provides a response that recommends a tailored learning path of textbooks, including both beginner-level and more advanced options.\"\n",
    "\n",
    "user_prompt = \"Hello there! I'm a beginner with a marketing background, and I'm really interested in learning about Python, data analytics, and machine learning. Can you recommend some books?\"\n",
    "\n",
    "response = get_response(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c95f808",
   "metadata": {},
   "source": [
    "### Adding guidelines for the learning advisor chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceedcb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "base_system_prompt = \"Act as a learning advisor who receives queries from users mentioning their background, experience, and goals, and accordingly provides a response that recommends a tailored learning path of textbooks, including both beginner-level and more advanced options.\"\n",
    "\n",
    "# Define behavior guidelines\n",
    "behavior_guidelines = \"If the user's query does not include details about their background, experience, or goals, kindly ask them to provide the missing information.\"\n",
    "\n",
    "# Define response guidelines\n",
    "response_guidelines = \"Don't recommend more than three textbooks in the learning path\"\n",
    "\n",
    "system_prompt = base_system_prompt + behavior_guidelines + response_guidelines\n",
    "user_prompt = \"Hey, I'm looking for courses on Python and data visualization. What do you recommend?\"\n",
    "response = get_response(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc50a6",
   "metadata": {},
   "source": [
    "## Incorporating external context in chatbot conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f84d58a",
   "metadata": {},
   "source": [
    "### Providing context through sample conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fd9fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Define the system prompt\n",
    "system_prompt = \"You are a customer service chatbot for MyPersonalDelivery, a delivery service that offers a wide range of delivery options for various items. You should respond to user queries in a gentle way.\"\n",
    "\n",
    "context_question = \"What types of items can be delivered using MyPersonalDelivery?\"\n",
    "context_answer = \"We deliver everything from everyday essentials such as groceries, medications, and documents to larger items like electronics, clothing, and furniture. However, please note that we currently do not offer delivery for hazardous materials or extremely fragile items requiring special handling.\"\n",
    "\n",
    "# Add the context to the model\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": context_question},\n",
    "            {\"role\": \"assistant\", \"content\": context_answer},\n",
    "            {\"role\": \"user\", \"content\": \"Do you deliver furniture?\"}])\n",
    "response = response.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f7f57",
   "metadata": {},
   "source": [
    "### Providing context through system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e8e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Define the system prompt\n",
    "system_prompt = f\"\"\"You are a customer service chatbot for MyPersonalDelivery whose service description is delimited by triple backticks. You should respond to user queries in a gentle way.\n",
    " ```{service_description}```\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"What benefits does MyPersonalDelivery offer?\"\n",
    "\n",
    "# Get the response to the user prompt\n",
    "response = get_response(system_prompt, user_prompt)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
